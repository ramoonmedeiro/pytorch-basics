{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A ideia desse projeto é realizar o treinamento, o salvamento, e o carregamento do modelo}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carregando a base de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "X = pd.read_csv(\"../../bases/bases/entradas_breast.csv\")\n",
    "y = pd.read_csv(\"../../bases/bases/saidas_breast.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "x_train = torch.tensor(np.array(x_train), dtype=torch.float)\n",
    "y_train = torch.tensor(np.array(y_train), dtype=torch.float)\n",
    "\n",
    "dataset = torch.utils.data.TensorDataset(x_train, y_train)\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classe para a rede neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class classificador_torch(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__() # pegando todos os atributos da super classe (nn.Module)\n",
    "        \n",
    "        self.dense0 = nn.Linear(in_features=30, out_features=16)\n",
    "        nn.init.uniform_(self.dense0.weight) # inicializando a primeira camada com pesos uniformemente aleatorio\n",
    "        self.activation0 = nn.ReLU()\n",
    "        self.dropout0 = nn.Dropout(0.2)\n",
    "        self.dense1 = nn.Linear(in_features=16, out_features=16)\n",
    "        nn.init.uniform_(self.dense1.weight)\n",
    "        self.activation1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(0.2)\n",
    "        self.dense2 = nn.Linear(in_features=16, out_features=1)\n",
    "        nn.init.uniform_(self.dense2.weight)\n",
    "        self.output = nn.Sigmoid()\n",
    "    def forward(self, x):\n",
    "        x = self.dense0(x)\n",
    "        x = self.activation0(x)\n",
    "        x = self.dropout0(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.activation1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.dense2(x)\n",
    "        x = self.output(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_torch = classificador_torch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(\n",
    "    params=model_torch.parameters(),\n",
    "    lr=0.001,\n",
    "    weight_decay=0.0001\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinamento da rede neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época 1 -> 39.22480618676474\n",
      "Época 2 -> 39.22480618676474\n",
      "Época 3 -> 39.22480618676474\n",
      "Época 4 -> 39.53488372093023\n",
      "Época 5 -> 39.06976744186046\n",
      "Época 6 -> 39.37984493166901\n",
      "Época 7 -> 39.53488372093023\n",
      "Época 8 -> 39.37984493166901\n",
      "Época 9 -> 39.37984493166901\n",
      "Época 10 -> 39.53488372093023\n",
      "Época 11 -> 39.22480618676474\n",
      "Época 12 -> 39.53488372093023\n",
      "Época 13 -> 39.68992242147756\n",
      "Época 14 -> 39.53488372093023\n",
      "Época 15 -> 39.22480618676474\n",
      "Época 16 -> 39.37984493166901\n",
      "Época 17 -> 39.37984493166901\n",
      "Época 18 -> 39.68992242147756\n",
      "Época 19 -> 39.53488372093023\n",
      "Época 20 -> 39.37984493166901\n",
      "Época 21 -> 39.37984493166901\n",
      "Época 22 -> 39.68992242147756\n",
      "Época 23 -> 39.53488372093023\n",
      "Época 24 -> 39.3798450203829\n",
      "Época 25 -> 39.33523404321005\n",
      "Época 26 -> 39.304376069889514\n",
      "Época 27 -> 39.68992242147756\n",
      "Época 28 -> 39.37984493166901\n",
      "Época 29 -> 39.68992242147756\n",
      "Época 30 -> 39.22480618676474\n",
      "Época 31 -> 39.37984493166901\n",
      "Época 32 -> 39.178443154623345\n",
      "Época 33 -> 37.55121477260146\n",
      "Época 34 -> 2.256218099663424\n",
      "Época 35 -> 0.5620167785605719\n",
      "Época 36 -> 0.5347499840481337\n",
      "Época 37 -> 0.537381146536317\n",
      "Época 38 -> 0.5385514144287553\n",
      "Época 39 -> 0.481465058271275\n",
      "Época 40 -> 0.46878012321716134\n",
      "Época 41 -> 0.4400707427845445\n",
      "Época 42 -> 0.4505989891152049\n",
      "Época 43 -> 0.40846060285734576\n",
      "Época 44 -> 0.42084828642911687\n",
      "Época 45 -> 0.39080476968787436\n",
      "Época 46 -> 0.37832899980766826\n",
      "Época 47 -> 0.36831641075916066\n",
      "Época 48 -> 0.3562840018854585\n",
      "Época 49 -> 0.3512509525861851\n",
      "Época 50 -> 0.32111214655776354\n",
      "Época 51 -> 0.3353279193126878\n",
      "Época 52 -> 0.3206989969625029\n",
      "Época 53 -> 0.30832051711027014\n",
      "Época 54 -> 0.33606076379155003\n",
      "Época 55 -> 0.30229207457498064\n",
      "Época 56 -> 0.2935989648103714\n",
      "Época 57 -> 0.26741015270005825\n",
      "Época 58 -> 0.26854564093573147\n",
      "Época 59 -> 0.31899348715710085\n",
      "Época 60 -> 0.25826609827751335\n",
      "Época 61 -> 0.3273977976898814\n",
      "Época 62 -> 0.30109611864006797\n",
      "Época 63 -> 0.256991388492806\n",
      "Época 64 -> 0.24880596631488136\n",
      "Época 65 -> 0.2557098971203316\n",
      "Época 66 -> 0.26372705867817237\n",
      "Época 67 -> 0.27955065147821295\n",
      "Época 68 -> 0.2597046167871287\n",
      "Época 69 -> 0.24376448503760403\n",
      "Época 70 -> 0.23153721931022267\n",
      "Época 71 -> 0.2235355309189059\n",
      "Época 72 -> 0.22196790766577387\n",
      "Época 73 -> 0.2639809924849244\n",
      "Época 74 -> 0.24456942566605502\n",
      "Época 75 -> 0.23987398591152456\n",
      "Época 76 -> 0.2602025092860987\n",
      "Época 77 -> 0.23349174285350843\n",
      "Época 78 -> 0.25444794506874197\n",
      "Época 79 -> 0.23104343840549157\n",
      "Época 80 -> 0.21395724388056023\n",
      "Época 81 -> 0.2355868124164814\n",
      "Época 82 -> 0.22623357462675073\n",
      "Época 83 -> 0.22772630145989878\n",
      "Época 84 -> 0.2599137752901676\n",
      "Época 85 -> 0.20783972961091718\n",
      "Época 86 -> 0.2150185790432747\n",
      "Época 87 -> 0.19704188363150107\n",
      "Época 88 -> 0.258481630492349\n",
      "Época 89 -> 0.2151027335677036\n",
      "Época 90 -> 0.21163911692971407\n",
      "Época 91 -> 0.21384650298805777\n",
      "Época 92 -> 0.20641369411591873\n",
      "Época 93 -> 0.20243446710844373\n",
      "Época 94 -> 0.20190264657139778\n",
      "Época 95 -> 0.21656290708153053\n",
      "Época 96 -> 0.2146055274318124\n",
      "Época 97 -> 0.22885278447769408\n",
      "Época 98 -> 0.23643492257525756\n",
      "Época 99 -> 0.1928883430569671\n",
      "Época 100 -> 0.20563513361090838\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.\n",
    "    for data in train_loader:\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model_torch.forward(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f\"Época {epoch+1} -> {running_loss/len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Salvando modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('dense0.weight',\n",
       "              tensor([[ 1.2263e-01,  1.1169e-01,  2.3952e-01, -7.7187e-02,  2.2062e-01,\n",
       "                       -1.9745e-01,  2.8558e-01,  3.4747e-01,  3.1558e-01,  1.6936e-02,\n",
       "                       -2.0932e-01, -3.7499e-02,  3.4204e-02, -2.2176e-01, -5.9369e-04,\n",
       "                       -2.6409e-02, -4.3655e-03, -5.1710e-03, -2.0608e-01, -2.5564e-02,\n",
       "                        1.2988e-01, -4.1874e-02,  5.3008e-03, -1.3753e-01, -1.0333e-01,\n",
       "                        2.1791e-02,  2.1244e-02, -1.7467e-01,  2.0537e-02, -9.2034e-02],\n",
       "                      [-1.2350e-01, -3.4853e-01, -4.5221e-01, -1.0295e-01,  3.0406e-01,\n",
       "                        3.2853e-01, -1.3058e-01, -1.7262e-01, -1.9801e-01, -1.4229e-01,\n",
       "                       -1.2931e-02, -2.0288e-03,  8.9746e-03, -2.2131e-03,  1.0036e-02,\n",
       "                        1.8167e-01, -1.6733e-01,  4.2853e-02,  1.1748e-01,  1.2033e-01,\n",
       "                       -4.5647e-02, -2.7942e-01, -1.3943e-01,  1.5019e-01, -1.3796e-01,\n",
       "                        2.4955e-02, -2.2918e-01,  8.2643e-02, -1.7910e-02,  3.0367e-01],\n",
       "                      [-1.1198e-02,  6.4461e-02, -5.6132e-02, -5.9466e-02,  7.3426e-05,\n",
       "                        2.9231e-07,  7.2224e-06,  1.7915e-09, -2.8037e-02,  9.3166e-22,\n",
       "                        2.9291e-02, -4.9691e-02, -2.5242e-02,  1.4036e-01,  5.9447e-37,\n",
       "                        4.0279e-12,  3.3482e-19,  5.4302e-37, -1.5402e-28,  4.3347e-37,\n",
       "                        2.4081e-02, -3.7253e-02,  9.9810e-02, -5.7620e-02, -1.0346e-13,\n",
       "                       -1.0164e-04,  1.4039e-03, -1.6771e-08,  5.2805e-02,  1.2365e-16],\n",
       "                      [ 1.4794e-01,  3.8899e-02,  2.9752e-01, -5.3911e-02, -2.0732e-02,\n",
       "                       -1.8026e-01,  1.0648e-01,  2.3451e-01,  5.1300e-01, -2.4163e-01,\n",
       "                        1.7643e-02,  8.7045e-02, -2.5795e-02, -2.7299e-01, -4.2554e-03,\n",
       "                        2.5065e-01, -1.3256e-02,  7.2864e-04, -2.0989e-01, -5.9624e-02,\n",
       "                        1.0163e-01, -1.2024e-02,  3.4366e-02, -1.3651e-01, -2.3295e-01,\n",
       "                        4.5120e-02, -1.6071e-01, -1.8079e-01,  7.6050e-02, -2.0263e-01],\n",
       "                      [-1.7696e-02, -2.3474e-01, -2.2804e-01, -1.3314e-01, -3.4169e-02,\n",
       "                        2.5036e-01, -1.3257e-01,  8.3511e-02, -9.5724e-02, -7.5558e-03,\n",
       "                        1.6354e-01,  7.1383e-04,  3.6455e-02, -3.8953e-02,  4.5830e-04,\n",
       "                       -5.4268e-03, -2.0607e-02,  3.3947e-04,  9.1364e-03, -7.1248e-04,\n",
       "                       -1.6213e-01, -5.9989e-02, -2.1733e-01, -1.4191e-01, -9.5747e-02,\n",
       "                       -9.1096e-02, -4.1572e-02,  1.2969e-02, -5.0705e-02,  3.6849e-02],\n",
       "                      [ 1.5459e-01,  2.7261e-01,  3.5959e-01,  8.0154e-02, -2.7071e-01,\n",
       "                       -1.6302e-01, -4.6829e-02,  1.4058e-01,  3.0561e-02,  4.6534e-01,\n",
       "                       -7.5116e-02, -4.3854e-02,  1.8546e-03,  7.9089e-02, -6.2133e-03,\n",
       "                       -8.4002e-02,  5.0219e-02,  8.3238e-02,  4.8361e-01, -5.1021e-03,\n",
       "                        1.5127e-01,  1.6858e-01,  2.8062e-01, -1.5594e-01,  5.8003e-02,\n",
       "                       -3.4461e-03, -4.7655e-02, -2.6766e-01,  5.3133e-03, -1.1469e-01],\n",
       "                      [-7.7298e-02, -7.6576e-02, -7.0936e-02, -5.6593e-02,  3.9883e-03,\n",
       "                       -1.9806e-02, -1.3519e-03,  1.1090e-02, -2.7844e-03, -7.5621e-12,\n",
       "                       -4.1850e-02, -4.2247e-02, -3.8580e-02, -1.0987e-01, -2.8538e-39,\n",
       "                       -1.2075e-19, -5.6910e-02,  2.2154e-06,  1.7799e-03,  1.4630e-34,\n",
       "                       -8.3859e-02, -8.0066e-02, -5.5760e-02,  6.1766e-02, -3.8496e-02,\n",
       "                        4.8249e-02,  3.1050e-02, -1.6703e-02,  1.4975e-02, -6.5787e-02],\n",
       "                      [-5.2287e-03, -9.3289e-03, -2.0849e-02, -1.2962e-02,  2.3808e-15,\n",
       "                        1.1668e-39,  1.0866e-13,  4.2637e-14,  1.2153e-24, -5.3247e-36,\n",
       "                        2.9654e-24, -2.7196e-11,  1.7687e-07, -1.0139e-02,  5.6990e-39,\n",
       "                       -4.3729e-39,  8.9906e-12,  3.4126e-11,  4.7428e-19,  3.1090e-12,\n",
       "                       -8.6348e-03, -1.1606e-03, -2.1473e-02, -2.3212e-02,  3.4981e-16,\n",
       "                       -6.4589e-15, -4.8909e-19,  8.3638e-24, -7.7031e-20,  4.9791e-40],\n",
       "                      [-9.9232e-03, -1.3130e-02, -5.3025e-03,  1.0385e-01, -3.8196e-02,\n",
       "                       -2.4901e-02, -5.2833e-02,  3.3540e-01,  1.2262e-01,  3.0668e-01,\n",
       "                        2.9790e-02, -1.2404e-01, -6.9571e-02, -2.0428e-01,  1.9191e-03,\n",
       "                        5.0024e-03, -1.1402e-02,  1.5104e-01,  2.5701e-02,  1.2114e-03,\n",
       "                       -4.6628e-02, -3.0311e-02,  2.7379e-02, -9.4599e-02, -9.7867e-02,\n",
       "                        8.4398e-02,  8.2068e-02, -6.0688e-02, -3.2473e-02, -6.5599e-02],\n",
       "                      [ 8.3709e-03, -2.0567e-01, -1.3299e-01, -1.8224e-01, -3.3594e-02,\n",
       "                       -2.8259e-02, -1.2011e-02, -4.0138e-04,  2.6723e-02,  4.6260e-03,\n",
       "                       -8.2161e-02,  7.8952e-02, -9.0078e-02,  6.3590e-02, -6.4425e-04,\n",
       "                       -1.6681e-01, -6.3024e-02, -3.2544e-04, -1.9348e-01, -7.0399e-04,\n",
       "                       -1.9184e-01, -1.8089e-01, -4.2664e-02,  2.1560e-02, -9.7241e-02,\n",
       "                       -6.8607e-02, -3.4594e-02, -7.3332e-02, -1.8239e-01, -3.9221e-02],\n",
       "                      [ 7.6014e-02,  8.6018e-02, -4.4350e-02, -4.1893e-02, -3.4989e-02,\n",
       "                        2.8142e-06,  7.2009e-06,  4.6679e-07,  3.5054e-02, -2.4692e-02,\n",
       "                        1.2126e-02, -1.8274e-03, -2.7197e-02, -4.8075e-02,  3.7708e-07,\n",
       "                        3.1318e-04,  1.6402e-08,  3.9731e-11, -1.0170e-02,  1.0000e-07,\n",
       "                       -2.8016e-03, -2.5184e-02, -4.8081e-02, -3.7351e-02,  6.8069e-02,\n",
       "                       -6.7904e-03, -5.9654e-04,  7.0574e-04, -4.0519e-02,  2.1434e-06],\n",
       "                      [-4.3374e-02, -4.5309e-02,  6.8232e-02, -4.9472e-02, -2.3649e-02,\n",
       "                       -3.8505e-02,  4.7165e-03,  2.4378e-02,  8.0818e-02,  1.3108e-02,\n",
       "                       -1.9918e-02,  4.1396e-03, -3.3936e-02, -2.9744e-02,  4.6704e-11,\n",
       "                       -9.0325e-17, -2.5635e-02, -4.9005e-39, -1.2790e-02,  1.1318e-09,\n",
       "                       -4.5442e-02, -5.1893e-02, -4.8814e-02, -8.4687e-04, -5.5131e-02,\n",
       "                       -1.7912e-02,  3.7838e-02, -2.8989e-02, -7.5065e-02, -5.1117e-02],\n",
       "                      [ 5.0582e-02,  9.4802e-02,  5.1779e-02, -5.4356e-02, -7.9249e-02,\n",
       "                        1.0149e-01, -4.0224e-02,  1.7407e-01,  3.3543e-02, -1.3821e-01,\n",
       "                        6.1820e-02,  6.5149e-02, -2.4993e-02, -2.6815e-01,  4.4867e-04,\n",
       "                        5.9609e-02,  2.6082e-02,  8.1756e-02, -4.9024e-02, -1.2184e-01,\n",
       "                        5.8448e-02, -2.8831e-02,  2.9315e-02, -7.7288e-02, -2.6794e-02,\n",
       "                       -4.0874e-02,  9.4537e-02, -2.5804e-01,  1.0199e-02, -6.4480e-02],\n",
       "                      [-3.9147e-01, -4.1023e-01, -3.7500e-01, -1.1323e-01,  1.3841e-01,\n",
       "                        1.5461e-01,  1.6210e-01, -2.3135e-01, -1.4814e-02,  1.0514e-01,\n",
       "                        1.2586e-04,  8.6404e-03, -1.5286e-03, -7.6527e-03,  1.4950e-02,\n",
       "                       -4.8004e-03, -3.5183e-01, -2.6444e-01,  1.1918e-01,  2.1257e-01,\n",
       "                       -4.8368e-01, -3.2139e-01, -3.8859e-01,  2.2881e-01,  2.5188e-02,\n",
       "                        4.9282e-02, -2.6326e-02,  2.9183e-01,  1.9184e-02,  4.9233e-01],\n",
       "                      [-2.2172e-01, -1.6884e-01, -4.2855e-01, -1.1262e-01,  6.1490e-02,\n",
       "                        5.1078e-02,  6.5723e-02, -1.3409e-01, -5.2845e-02, -7.2006e-02,\n",
       "                       -3.3375e-02, -2.4600e-03,  2.0025e-03, -1.5293e-02,  2.4216e-02,\n",
       "                        9.6263e-02, -2.2381e-01, -2.4300e-01, -9.8283e-02,  2.2035e-01,\n",
       "                       -3.7196e-01, -6.9252e-02, -3.1211e-01,  2.0269e-01,  1.9227e-02,\n",
       "                        3.3251e-02, -2.5611e-02,  2.0538e-01,  6.1497e-03,  4.5483e-01],\n",
       "                      [-1.2899e-02, -4.0590e-02, -7.4024e-02,  7.5500e-02,  1.9450e-33,\n",
       "                        6.0225e-09, -2.5415e-10,  3.0561e-03, -3.3419e-05,  3.7325e-02,\n",
       "                        1.7204e-02, -6.5051e-02, -8.0910e-02, -1.0682e-01,  3.2687e-18,\n",
       "                       -2.9804e-40, -7.0408e-03,  5.0888e-05,  7.1937e-40,  3.2230e-27,\n",
       "                       -5.7000e-02, -4.0790e-02, -3.8992e-02, -9.4903e-02,  1.4392e-09,\n",
       "                       -2.5960e-03,  1.1120e-02, -5.2276e-02, -4.2190e-02,  1.1367e-39]])),\n",
       "             ('dense0.bias',\n",
       "              tensor([ 2.0999e-01, -6.7234e-01, -1.4326e-03,  2.1796e-01, -1.3180e-01,\n",
       "                       6.3398e-01, -1.2677e-02, -2.5478e-11,  5.8232e-02, -9.8790e-02,\n",
       "                      -7.9640e-03, -1.2238e-02,  1.2967e-01, -8.5138e-01, -6.8642e-01,\n",
       "                      -1.5517e-04])),\n",
       "             ('dense1.weight',\n",
       "              tensor([[-8.2485e-02, -2.3540e-02, -2.7439e-02, -2.8420e-02, -1.8269e-02,\n",
       "                       -4.3114e-03,  1.0006e-01, -2.3901e-02, -9.3482e-03, -1.0707e-02,\n",
       "                        3.6181e-02,  5.0190e-02, -2.3132e-02, -7.1292e-02, -6.8409e-02,\n",
       "                        2.0783e-02],\n",
       "                      [ 1.5482e-02,  4.5302e-02, -1.0739e-02, -2.6875e-02, -2.9070e-02,\n",
       "                       -7.3610e-02,  1.1314e-01,  8.3738e-07,  4.1602e-02, -5.2970e-05,\n",
       "                       -1.2823e-02,  1.0572e-01,  3.1736e-02,  9.1674e-02,  1.6929e-01,\n",
       "                        1.1972e-01],\n",
       "                      [-1.6408e-02,  1.6185e-01, -3.5368e-02, -1.4523e-02,  6.9974e-02,\n",
       "                       -1.1472e-02,  8.6703e-02,  1.6440e-02,  1.6923e-02, -3.6180e-02,\n",
       "                       -3.4509e-02, -7.0867e-04,  6.9934e-03,  1.4974e-01, -1.3287e-01,\n",
       "                        2.6095e-02],\n",
       "                      [ 5.3538e-02, -8.5705e-02,  1.0411e-01,  1.2844e-01, -4.4173e-02,\n",
       "                        1.5558e-01, -3.5813e-02,  6.2246e-30,  9.3809e-02, -9.6212e-02,\n",
       "                        7.6067e-02, -1.1599e-02, -6.9169e-02, -1.5782e-01, -8.8767e-02,\n",
       "                       -4.3142e-02],\n",
       "                      [-2.2723e-02,  1.3715e-01, -6.0320e-02,  4.6470e-03,  1.2663e-01,\n",
       "                        7.1136e-02,  7.0016e-02, -1.3811e-02,  1.2731e-02,  1.1745e-01,\n",
       "                       -4.3598e-02,  1.4160e-02, -9.0907e-03,  2.0195e-01, -1.1024e-01,\n",
       "                        2.1274e-02],\n",
       "                      [-1.0492e-02,  2.7716e-03,  1.1897e-02,  3.7896e-03, -1.1641e-01,\n",
       "                       -8.0592e-02,  3.6313e-02, -1.1439e-02,  8.2634e-02, -6.6819e-04,\n",
       "                        2.7303e-02, -2.4566e-02, -7.3936e-03,  7.7425e-02,  2.4145e-01,\n",
       "                       -1.6840e-03],\n",
       "                      [ 9.0557e-02, -4.1767e-02, -1.7998e-02,  5.6648e-03, -9.0566e-02,\n",
       "                       -3.5798e-03,  3.7507e-02, -1.0660e-02,  7.0756e-02, -2.7107e-02,\n",
       "                        4.9094e-03,  8.7838e-03,  1.3983e-01, -1.8907e-01, -1.4449e-01,\n",
       "                       -3.4039e-02],\n",
       "                      [ 3.3321e-02,  1.0888e-01, -2.2071e-02, -4.3206e-02,  9.4947e-02,\n",
       "                       -9.5069e-02,  3.1783e-02, -1.5161e-02,  2.3250e-02, -4.1649e-02,\n",
       "                       -2.3614e-02,  2.3231e-02, -8.8274e-03,  1.3667e-01,  6.2457e-02,\n",
       "                        5.5917e-02],\n",
       "                      [-1.4933e-02,  1.0170e-01, -4.5878e-02,  7.0439e-03,  1.8008e-01,\n",
       "                       -1.3275e-01, -3.0419e-02, -2.5937e-03, -9.7167e-02, -6.2204e-03,\n",
       "                       -3.4592e-02, -3.6437e-02,  4.7302e-03,  1.5677e-01,  8.2325e-02,\n",
       "                       -9.4312e-03],\n",
       "                      [ 1.0735e-02, -2.9685e-02,  4.4871e-02,  1.0551e-01, -3.4763e-02,\n",
       "                        4.0058e-02,  1.0924e-02,  8.3672e-17,  4.2399e-02, -2.3231e-02,\n",
       "                        1.2166e-02, -2.9619e-02, -2.6857e-02, -7.3292e-02,  5.1012e-02,\n",
       "                       -7.2419e-03],\n",
       "                      [-2.0079e-02, -4.9645e-02,  6.9039e-02, -1.2775e-01, -1.1265e-01,\n",
       "                        1.6043e-01, -9.0262e-03, -1.5040e-02,  1.4764e-01, -6.4859e-02,\n",
       "                       -5.2629e-02, -8.6203e-03,  4.1132e-02, -7.9731e-02, -9.7275e-02,\n",
       "                       -3.2345e-02],\n",
       "                      [ 5.6429e-02, -4.8346e-02, -5.1959e-02,  7.4081e-02,  6.1282e-02,\n",
       "                        3.0311e-02, -3.5795e-02, -2.8963e-03, -6.3572e-02,  5.1106e-02,\n",
       "                        1.4782e-01, -3.7994e-02,  1.0210e-01, -1.3984e-01, -1.0062e-01,\n",
       "                       -2.1808e-02],\n",
       "                      [-5.5487e-02, -4.5032e-02, -3.3226e-02, -8.1705e-02, -3.1145e-02,\n",
       "                        5.7988e-02,  1.0103e-01, -2.1545e-02,  1.5033e-01, -5.8747e-02,\n",
       "                        6.0725e-02, -7.0576e-03,  3.6442e-02, -5.7187e-02, -4.9998e-02,\n",
       "                        5.3611e-02],\n",
       "                      [ 3.5322e-02, -3.9876e-02,  9.2220e-02, -7.6616e-02,  7.8949e-03,\n",
       "                        1.0834e-01, -2.6940e-02,  2.1503e-02,  5.6438e-02,  6.9721e-02,\n",
       "                        5.1719e-02, -2.9181e-02, -3.9645e-02, -1.0920e-01, -1.0780e-01,\n",
       "                       -1.2604e-02],\n",
       "                      [ 5.8363e-02, -8.0595e-02,  1.5657e-01,  7.0856e-02, -2.8748e-02,\n",
       "                        2.6437e-01,  8.6127e-02,  1.0911e-02,  1.0136e-01, -3.8523e-02,\n",
       "                        1.8300e-01, -3.2388e-02,  4.6376e-04, -1.2096e-01, -8.9195e-02,\n",
       "                        2.1308e-02],\n",
       "                      [ 2.2658e-02, -2.5680e-02,  6.0670e-02,  4.1589e-02,  3.5398e-04,\n",
       "                        8.0818e-02,  4.5514e-02, -2.1055e-02,  6.1814e-02,  3.7307e-02,\n",
       "                        9.2019e-02,  9.5461e-02,  1.9705e-02, -9.2049e-02, -2.5239e-02,\n",
       "                        1.2954e-02]])),\n",
       "             ('dense1.bias',\n",
       "              tensor([-0.0763, -0.6086, -0.4554,  0.7723, -0.4386, -0.7675,  0.8333, -0.6594,\n",
       "                      -0.7577,  0.3735,  0.8619,  0.5168,  0.5441,  0.5719,  0.8667,  0.6026])),\n",
       "             ('dense2.weight',\n",
       "              tensor([[ 0.1443, -0.0834, -0.0786,  0.1125, -0.0208, -0.0736,  0.0547, -0.0874,\n",
       "                       -0.0796,  0.0139,  0.1036,  0.0396,  0.1223,  0.1913,  0.1414,  0.0864]])),\n",
       "             ('dense2.bias', tensor([0.8885]))])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_torch.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_torch.state_dict(), \"modelo.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carregando modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class classificador_torch2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__() # pegando todos os atributos da super classe (nn.Module)\n",
    "        \n",
    "        self.dense0 = nn.Linear(in_features=30, out_features=16)\n",
    "        nn.init.uniform_(self.dense0.weight) # inicializando a primeira camada com pesos uniformemente aleatorio\n",
    "        self.activation0 = nn.ReLU()\n",
    "        self.dropout0 = nn.Dropout(0.2)\n",
    "        self.dense1 = nn.Linear(in_features=16, out_features=16)\n",
    "        nn.init.uniform_(self.dense1.weight)\n",
    "        self.activation1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(0.2)\n",
    "        self.dense2 = nn.Linear(in_features=16, out_features=1)\n",
    "        nn.init.uniform_(self.dense2.weight)\n",
    "        self.output = nn.Sigmoid()\n",
    "    def forward(self, x):\n",
    "        x = self.dense0(x)\n",
    "        x = self.activation0(x)\n",
    "        x = self.dropout0(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.activation1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.dense2(x)\n",
    "        x = self.output(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_loaded = classificador_torch2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load(\"modelo.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('dense0.weight',\n",
       "              tensor([[ 1.2263e-01,  1.1169e-01,  2.3952e-01, -7.7187e-02,  2.2062e-01,\n",
       "                       -1.9745e-01,  2.8558e-01,  3.4747e-01,  3.1558e-01,  1.6936e-02,\n",
       "                       -2.0932e-01, -3.7499e-02,  3.4204e-02, -2.2176e-01, -5.9369e-04,\n",
       "                       -2.6409e-02, -4.3655e-03, -5.1710e-03, -2.0608e-01, -2.5564e-02,\n",
       "                        1.2988e-01, -4.1874e-02,  5.3008e-03, -1.3753e-01, -1.0333e-01,\n",
       "                        2.1791e-02,  2.1244e-02, -1.7467e-01,  2.0537e-02, -9.2034e-02],\n",
       "                      [-1.2350e-01, -3.4853e-01, -4.5221e-01, -1.0295e-01,  3.0406e-01,\n",
       "                        3.2853e-01, -1.3058e-01, -1.7262e-01, -1.9801e-01, -1.4229e-01,\n",
       "                       -1.2931e-02, -2.0288e-03,  8.9746e-03, -2.2131e-03,  1.0036e-02,\n",
       "                        1.8167e-01, -1.6733e-01,  4.2853e-02,  1.1748e-01,  1.2033e-01,\n",
       "                       -4.5647e-02, -2.7942e-01, -1.3943e-01,  1.5019e-01, -1.3796e-01,\n",
       "                        2.4955e-02, -2.2918e-01,  8.2643e-02, -1.7910e-02,  3.0367e-01],\n",
       "                      [-1.1198e-02,  6.4461e-02, -5.6132e-02, -5.9466e-02,  7.3426e-05,\n",
       "                        2.9231e-07,  7.2224e-06,  1.7915e-09, -2.8037e-02,  9.3166e-22,\n",
       "                        2.9291e-02, -4.9691e-02, -2.5242e-02,  1.4036e-01,  5.9447e-37,\n",
       "                        4.0279e-12,  3.3482e-19,  5.4302e-37, -1.5402e-28,  4.3347e-37,\n",
       "                        2.4081e-02, -3.7253e-02,  9.9810e-02, -5.7620e-02, -1.0346e-13,\n",
       "                       -1.0164e-04,  1.4039e-03, -1.6771e-08,  5.2805e-02,  1.2365e-16],\n",
       "                      [ 1.4794e-01,  3.8899e-02,  2.9752e-01, -5.3911e-02, -2.0732e-02,\n",
       "                       -1.8026e-01,  1.0648e-01,  2.3451e-01,  5.1300e-01, -2.4163e-01,\n",
       "                        1.7643e-02,  8.7045e-02, -2.5795e-02, -2.7299e-01, -4.2554e-03,\n",
       "                        2.5065e-01, -1.3256e-02,  7.2864e-04, -2.0989e-01, -5.9624e-02,\n",
       "                        1.0163e-01, -1.2024e-02,  3.4366e-02, -1.3651e-01, -2.3295e-01,\n",
       "                        4.5120e-02, -1.6071e-01, -1.8079e-01,  7.6050e-02, -2.0263e-01],\n",
       "                      [-1.7696e-02, -2.3474e-01, -2.2804e-01, -1.3314e-01, -3.4169e-02,\n",
       "                        2.5036e-01, -1.3257e-01,  8.3511e-02, -9.5724e-02, -7.5558e-03,\n",
       "                        1.6354e-01,  7.1383e-04,  3.6455e-02, -3.8953e-02,  4.5830e-04,\n",
       "                       -5.4268e-03, -2.0607e-02,  3.3947e-04,  9.1364e-03, -7.1248e-04,\n",
       "                       -1.6213e-01, -5.9989e-02, -2.1733e-01, -1.4191e-01, -9.5747e-02,\n",
       "                       -9.1096e-02, -4.1572e-02,  1.2969e-02, -5.0705e-02,  3.6849e-02],\n",
       "                      [ 1.5459e-01,  2.7261e-01,  3.5959e-01,  8.0154e-02, -2.7071e-01,\n",
       "                       -1.6302e-01, -4.6829e-02,  1.4058e-01,  3.0561e-02,  4.6534e-01,\n",
       "                       -7.5116e-02, -4.3854e-02,  1.8546e-03,  7.9089e-02, -6.2133e-03,\n",
       "                       -8.4002e-02,  5.0219e-02,  8.3238e-02,  4.8361e-01, -5.1021e-03,\n",
       "                        1.5127e-01,  1.6858e-01,  2.8062e-01, -1.5594e-01,  5.8003e-02,\n",
       "                       -3.4461e-03, -4.7655e-02, -2.6766e-01,  5.3133e-03, -1.1469e-01],\n",
       "                      [-7.7298e-02, -7.6576e-02, -7.0936e-02, -5.6593e-02,  3.9883e-03,\n",
       "                       -1.9806e-02, -1.3519e-03,  1.1090e-02, -2.7844e-03, -7.5621e-12,\n",
       "                       -4.1850e-02, -4.2247e-02, -3.8580e-02, -1.0987e-01, -2.8538e-39,\n",
       "                       -1.2075e-19, -5.6910e-02,  2.2154e-06,  1.7799e-03,  1.4630e-34,\n",
       "                       -8.3859e-02, -8.0066e-02, -5.5760e-02,  6.1766e-02, -3.8496e-02,\n",
       "                        4.8249e-02,  3.1050e-02, -1.6703e-02,  1.4975e-02, -6.5787e-02],\n",
       "                      [-5.2287e-03, -9.3289e-03, -2.0849e-02, -1.2962e-02,  2.3808e-15,\n",
       "                        1.1668e-39,  1.0866e-13,  4.2637e-14,  1.2153e-24, -5.3247e-36,\n",
       "                        2.9654e-24, -2.7196e-11,  1.7687e-07, -1.0139e-02,  5.6990e-39,\n",
       "                       -4.3729e-39,  8.9906e-12,  3.4126e-11,  4.7428e-19,  3.1090e-12,\n",
       "                       -8.6348e-03, -1.1606e-03, -2.1473e-02, -2.3212e-02,  3.4981e-16,\n",
       "                       -6.4589e-15, -4.8909e-19,  8.3638e-24, -7.7031e-20,  4.9791e-40],\n",
       "                      [-9.9232e-03, -1.3130e-02, -5.3025e-03,  1.0385e-01, -3.8196e-02,\n",
       "                       -2.4901e-02, -5.2833e-02,  3.3540e-01,  1.2262e-01,  3.0668e-01,\n",
       "                        2.9790e-02, -1.2404e-01, -6.9571e-02, -2.0428e-01,  1.9191e-03,\n",
       "                        5.0024e-03, -1.1402e-02,  1.5104e-01,  2.5701e-02,  1.2114e-03,\n",
       "                       -4.6628e-02, -3.0311e-02,  2.7379e-02, -9.4599e-02, -9.7867e-02,\n",
       "                        8.4398e-02,  8.2068e-02, -6.0688e-02, -3.2473e-02, -6.5599e-02],\n",
       "                      [ 8.3709e-03, -2.0567e-01, -1.3299e-01, -1.8224e-01, -3.3594e-02,\n",
       "                       -2.8259e-02, -1.2011e-02, -4.0138e-04,  2.6723e-02,  4.6260e-03,\n",
       "                       -8.2161e-02,  7.8952e-02, -9.0078e-02,  6.3590e-02, -6.4425e-04,\n",
       "                       -1.6681e-01, -6.3024e-02, -3.2544e-04, -1.9348e-01, -7.0399e-04,\n",
       "                       -1.9184e-01, -1.8089e-01, -4.2664e-02,  2.1560e-02, -9.7241e-02,\n",
       "                       -6.8607e-02, -3.4594e-02, -7.3332e-02, -1.8239e-01, -3.9221e-02],\n",
       "                      [ 7.6014e-02,  8.6018e-02, -4.4350e-02, -4.1893e-02, -3.4989e-02,\n",
       "                        2.8142e-06,  7.2009e-06,  4.6679e-07,  3.5054e-02, -2.4692e-02,\n",
       "                        1.2126e-02, -1.8274e-03, -2.7197e-02, -4.8075e-02,  3.7708e-07,\n",
       "                        3.1318e-04,  1.6402e-08,  3.9731e-11, -1.0170e-02,  1.0000e-07,\n",
       "                       -2.8016e-03, -2.5184e-02, -4.8081e-02, -3.7351e-02,  6.8069e-02,\n",
       "                       -6.7904e-03, -5.9654e-04,  7.0574e-04, -4.0519e-02,  2.1434e-06],\n",
       "                      [-4.3374e-02, -4.5309e-02,  6.8232e-02, -4.9472e-02, -2.3649e-02,\n",
       "                       -3.8505e-02,  4.7165e-03,  2.4378e-02,  8.0818e-02,  1.3108e-02,\n",
       "                       -1.9918e-02,  4.1396e-03, -3.3936e-02, -2.9744e-02,  4.6704e-11,\n",
       "                       -9.0325e-17, -2.5635e-02, -4.9005e-39, -1.2790e-02,  1.1318e-09,\n",
       "                       -4.5442e-02, -5.1893e-02, -4.8814e-02, -8.4687e-04, -5.5131e-02,\n",
       "                       -1.7912e-02,  3.7838e-02, -2.8989e-02, -7.5065e-02, -5.1117e-02],\n",
       "                      [ 5.0582e-02,  9.4802e-02,  5.1779e-02, -5.4356e-02, -7.9249e-02,\n",
       "                        1.0149e-01, -4.0224e-02,  1.7407e-01,  3.3543e-02, -1.3821e-01,\n",
       "                        6.1820e-02,  6.5149e-02, -2.4993e-02, -2.6815e-01,  4.4867e-04,\n",
       "                        5.9609e-02,  2.6082e-02,  8.1756e-02, -4.9024e-02, -1.2184e-01,\n",
       "                        5.8448e-02, -2.8831e-02,  2.9315e-02, -7.7288e-02, -2.6794e-02,\n",
       "                       -4.0874e-02,  9.4537e-02, -2.5804e-01,  1.0199e-02, -6.4480e-02],\n",
       "                      [-3.9147e-01, -4.1023e-01, -3.7500e-01, -1.1323e-01,  1.3841e-01,\n",
       "                        1.5461e-01,  1.6210e-01, -2.3135e-01, -1.4814e-02,  1.0514e-01,\n",
       "                        1.2586e-04,  8.6404e-03, -1.5286e-03, -7.6527e-03,  1.4950e-02,\n",
       "                       -4.8004e-03, -3.5183e-01, -2.6444e-01,  1.1918e-01,  2.1257e-01,\n",
       "                       -4.8368e-01, -3.2139e-01, -3.8859e-01,  2.2881e-01,  2.5188e-02,\n",
       "                        4.9282e-02, -2.6326e-02,  2.9183e-01,  1.9184e-02,  4.9233e-01],\n",
       "                      [-2.2172e-01, -1.6884e-01, -4.2855e-01, -1.1262e-01,  6.1490e-02,\n",
       "                        5.1078e-02,  6.5723e-02, -1.3409e-01, -5.2845e-02, -7.2006e-02,\n",
       "                       -3.3375e-02, -2.4600e-03,  2.0025e-03, -1.5293e-02,  2.4216e-02,\n",
       "                        9.6263e-02, -2.2381e-01, -2.4300e-01, -9.8283e-02,  2.2035e-01,\n",
       "                       -3.7196e-01, -6.9252e-02, -3.1211e-01,  2.0269e-01,  1.9227e-02,\n",
       "                        3.3251e-02, -2.5611e-02,  2.0538e-01,  6.1497e-03,  4.5483e-01],\n",
       "                      [-1.2899e-02, -4.0590e-02, -7.4024e-02,  7.5500e-02,  1.9450e-33,\n",
       "                        6.0225e-09, -2.5415e-10,  3.0561e-03, -3.3419e-05,  3.7325e-02,\n",
       "                        1.7204e-02, -6.5051e-02, -8.0910e-02, -1.0682e-01,  3.2687e-18,\n",
       "                       -2.9804e-40, -7.0408e-03,  5.0888e-05,  7.1937e-40,  3.2230e-27,\n",
       "                       -5.7000e-02, -4.0790e-02, -3.8992e-02, -9.4903e-02,  1.4392e-09,\n",
       "                       -2.5960e-03,  1.1120e-02, -5.2276e-02, -4.2190e-02,  1.1367e-39]])),\n",
       "             ('dense0.bias',\n",
       "              tensor([ 2.0999e-01, -6.7234e-01, -1.4326e-03,  2.1796e-01, -1.3180e-01,\n",
       "                       6.3398e-01, -1.2677e-02, -2.5478e-11,  5.8232e-02, -9.8790e-02,\n",
       "                      -7.9640e-03, -1.2238e-02,  1.2967e-01, -8.5138e-01, -6.8642e-01,\n",
       "                      -1.5517e-04])),\n",
       "             ('dense1.weight',\n",
       "              tensor([[-8.2485e-02, -2.3540e-02, -2.7439e-02, -2.8420e-02, -1.8269e-02,\n",
       "                       -4.3114e-03,  1.0006e-01, -2.3901e-02, -9.3482e-03, -1.0707e-02,\n",
       "                        3.6181e-02,  5.0190e-02, -2.3132e-02, -7.1292e-02, -6.8409e-02,\n",
       "                        2.0783e-02],\n",
       "                      [ 1.5482e-02,  4.5302e-02, -1.0739e-02, -2.6875e-02, -2.9070e-02,\n",
       "                       -7.3610e-02,  1.1314e-01,  8.3738e-07,  4.1602e-02, -5.2970e-05,\n",
       "                       -1.2823e-02,  1.0572e-01,  3.1736e-02,  9.1674e-02,  1.6929e-01,\n",
       "                        1.1972e-01],\n",
       "                      [-1.6408e-02,  1.6185e-01, -3.5368e-02, -1.4523e-02,  6.9974e-02,\n",
       "                       -1.1472e-02,  8.6703e-02,  1.6440e-02,  1.6923e-02, -3.6180e-02,\n",
       "                       -3.4509e-02, -7.0867e-04,  6.9934e-03,  1.4974e-01, -1.3287e-01,\n",
       "                        2.6095e-02],\n",
       "                      [ 5.3538e-02, -8.5705e-02,  1.0411e-01,  1.2844e-01, -4.4173e-02,\n",
       "                        1.5558e-01, -3.5813e-02,  6.2246e-30,  9.3809e-02, -9.6212e-02,\n",
       "                        7.6067e-02, -1.1599e-02, -6.9169e-02, -1.5782e-01, -8.8767e-02,\n",
       "                       -4.3142e-02],\n",
       "                      [-2.2723e-02,  1.3715e-01, -6.0320e-02,  4.6470e-03,  1.2663e-01,\n",
       "                        7.1136e-02,  7.0016e-02, -1.3811e-02,  1.2731e-02,  1.1745e-01,\n",
       "                       -4.3598e-02,  1.4160e-02, -9.0907e-03,  2.0195e-01, -1.1024e-01,\n",
       "                        2.1274e-02],\n",
       "                      [-1.0492e-02,  2.7716e-03,  1.1897e-02,  3.7896e-03, -1.1641e-01,\n",
       "                       -8.0592e-02,  3.6313e-02, -1.1439e-02,  8.2634e-02, -6.6819e-04,\n",
       "                        2.7303e-02, -2.4566e-02, -7.3936e-03,  7.7425e-02,  2.4145e-01,\n",
       "                       -1.6840e-03],\n",
       "                      [ 9.0557e-02, -4.1767e-02, -1.7998e-02,  5.6648e-03, -9.0566e-02,\n",
       "                       -3.5798e-03,  3.7507e-02, -1.0660e-02,  7.0756e-02, -2.7107e-02,\n",
       "                        4.9094e-03,  8.7838e-03,  1.3983e-01, -1.8907e-01, -1.4449e-01,\n",
       "                       -3.4039e-02],\n",
       "                      [ 3.3321e-02,  1.0888e-01, -2.2071e-02, -4.3206e-02,  9.4947e-02,\n",
       "                       -9.5069e-02,  3.1783e-02, -1.5161e-02,  2.3250e-02, -4.1649e-02,\n",
       "                       -2.3614e-02,  2.3231e-02, -8.8274e-03,  1.3667e-01,  6.2457e-02,\n",
       "                        5.5917e-02],\n",
       "                      [-1.4933e-02,  1.0170e-01, -4.5878e-02,  7.0439e-03,  1.8008e-01,\n",
       "                       -1.3275e-01, -3.0419e-02, -2.5937e-03, -9.7167e-02, -6.2204e-03,\n",
       "                       -3.4592e-02, -3.6437e-02,  4.7302e-03,  1.5677e-01,  8.2325e-02,\n",
       "                       -9.4312e-03],\n",
       "                      [ 1.0735e-02, -2.9685e-02,  4.4871e-02,  1.0551e-01, -3.4763e-02,\n",
       "                        4.0058e-02,  1.0924e-02,  8.3672e-17,  4.2399e-02, -2.3231e-02,\n",
       "                        1.2166e-02, -2.9619e-02, -2.6857e-02, -7.3292e-02,  5.1012e-02,\n",
       "                       -7.2419e-03],\n",
       "                      [-2.0079e-02, -4.9645e-02,  6.9039e-02, -1.2775e-01, -1.1265e-01,\n",
       "                        1.6043e-01, -9.0262e-03, -1.5040e-02,  1.4764e-01, -6.4859e-02,\n",
       "                       -5.2629e-02, -8.6203e-03,  4.1132e-02, -7.9731e-02, -9.7275e-02,\n",
       "                       -3.2345e-02],\n",
       "                      [ 5.6429e-02, -4.8346e-02, -5.1959e-02,  7.4081e-02,  6.1282e-02,\n",
       "                        3.0311e-02, -3.5795e-02, -2.8963e-03, -6.3572e-02,  5.1106e-02,\n",
       "                        1.4782e-01, -3.7994e-02,  1.0210e-01, -1.3984e-01, -1.0062e-01,\n",
       "                       -2.1808e-02],\n",
       "                      [-5.5487e-02, -4.5032e-02, -3.3226e-02, -8.1705e-02, -3.1145e-02,\n",
       "                        5.7988e-02,  1.0103e-01, -2.1545e-02,  1.5033e-01, -5.8747e-02,\n",
       "                        6.0725e-02, -7.0576e-03,  3.6442e-02, -5.7187e-02, -4.9998e-02,\n",
       "                        5.3611e-02],\n",
       "                      [ 3.5322e-02, -3.9876e-02,  9.2220e-02, -7.6616e-02,  7.8949e-03,\n",
       "                        1.0834e-01, -2.6940e-02,  2.1503e-02,  5.6438e-02,  6.9721e-02,\n",
       "                        5.1719e-02, -2.9181e-02, -3.9645e-02, -1.0920e-01, -1.0780e-01,\n",
       "                       -1.2604e-02],\n",
       "                      [ 5.8363e-02, -8.0595e-02,  1.5657e-01,  7.0856e-02, -2.8748e-02,\n",
       "                        2.6437e-01,  8.6127e-02,  1.0911e-02,  1.0136e-01, -3.8523e-02,\n",
       "                        1.8300e-01, -3.2388e-02,  4.6376e-04, -1.2096e-01, -8.9195e-02,\n",
       "                        2.1308e-02],\n",
       "                      [ 2.2658e-02, -2.5680e-02,  6.0670e-02,  4.1589e-02,  3.5398e-04,\n",
       "                        8.0818e-02,  4.5514e-02, -2.1055e-02,  6.1814e-02,  3.7307e-02,\n",
       "                        9.2019e-02,  9.5461e-02,  1.9705e-02, -9.2049e-02, -2.5239e-02,\n",
       "                        1.2954e-02]])),\n",
       "             ('dense1.bias',\n",
       "              tensor([-0.0763, -0.6086, -0.4554,  0.7723, -0.4386, -0.7675,  0.8333, -0.6594,\n",
       "                      -0.7577,  0.3735,  0.8619,  0.5168,  0.5441,  0.5719,  0.8667,  0.6026])),\n",
       "             ('dense2.weight',\n",
       "              tensor([[ 0.1443, -0.0834, -0.0786,  0.1125, -0.0208, -0.0736,  0.0547, -0.0874,\n",
       "                       -0.0796,  0.0139,  0.1036,  0.0396,  0.1223,  0.1913,  0.1414,  0.0864]])),\n",
       "             ('dense2.bias', tensor([0.8885]))])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_loaded.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "classificador_torch2(\n",
       "  (dense0): Linear(in_features=30, out_features=16, bias=True)\n",
       "  (activation0): ReLU()\n",
       "  (dropout0): Dropout(p=0.2, inplace=False)\n",
       "  (dense1): Linear(in_features=16, out_features=16, bias=True)\n",
       "  (activation1): ReLU()\n",
       "  (dropout1): Dropout(p=0.2, inplace=False)\n",
       "  (dense2): Linear(in_features=16, out_features=1, bias=True)\n",
       "  (output): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_loaded.eval()\n",
    "# a partir daqui p modelo está pronto para realizar inferencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
